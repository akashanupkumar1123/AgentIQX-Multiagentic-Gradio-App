# -*- coding: utf-8 -*-
"""AGENTIQX_TEST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aZoWqo7E_N5YbBmNStoWSmbkq1CLt-Ji
"""

# Update package lists and install ffmpeg system package once
!apt-get update && apt-get install -y ffmpeg

# Python packages - install or upgrade where applicable
!pip install --upgrade --no-cache-dir \
    python-dotenv \
    sentence-transformers \
    faiss-cpu \
    gtts \
    pymupdf \
    PyPDF2 \
    openai \
    requests \
    torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118  # CUDA 11.8 wheels; adjust if needed

# Whisper (OpenAI Whisper) from official repo
!pip install --upgrade --no-cache-dir git+https://github.com/openai/whisper.git

# Faster Whisper - optimized Whisper implementation
!pip install --upgrade --no-cache-dir faster-whisper

import torch, whisper, faiss, sentence_transformers, gtts, fitz, PyPDF2, requests

print("PyTorch version:", torch.__version__)
print("Whisper version:", whisper.__version__)
print("FAISS version:", faiss.__version__)
print("Sentence Transformers version:", sentence_transformers.__version__)
print("gTTS version:", gtts.__version__)
print("PyMuPDF version:", fitz.__doc__)
print("PyPDF2 version:", PyPDF2.__version__)
print("Requests version:", requests.__version__)

import os, shutil

# Create folders
os.makedirs("utils", exist_ok=True)
os.makedirs("agents", exist_ok=True)

# Move utils files
for file in ["chunking_utils.py", "emails_utils.py", "faiss_utils.py",
             "summary_agent.py", "transcript_utils.py", "tts_utils.py", "__init__.py"]:
    if os.path.exists(file):
        shutil.move(file, f"utils/{file}")

# Move agents files
for file in ["pdf_agent.py", "explain_agent.py", "rag_agent.py",
             "video_agent.py", "embed_agent.py", "llm_agent.py", "ollama_agent.py"]:
    if os.path.exists(file):
        shutil.move(file, f"agents/{file}")

import os, shutil

# Make sure folders exist
os.makedirs("assets", exist_ok=True)

# Move the uploaded files
shutil.move("style.css", "assets/style.css")
shutil.move("app.py", "app.py")

import os

print("Root contents:", os.listdir())
print("utils/:", os.listdir("utils"))
print("agents/:", os.listdir("agents"))
print("assets/:", os.listdir("assets"))

import sys
sys.path.append("/content")

with open(".env", "w") as f:
    f.write("SENDER_EMAIL=akashanupkumar1123@gmail.com\n")
    f.write("SENDER_PASSWORD=dzpxtpliniwescfa\n")

from dotenv import load_dotenv
import os

load_dotenv()

print("Email:", os.getenv("SENDER_EMAIL"))

# Install fpdf if you want to generate a PDF sample via code
!pip install -q fpdf

from fpdf import FPDF
import os

# 1. Create a simple sample PDF locally
def create_sample_pdf(filename="sample.pdf"):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    sample_text = """This is a sample PDF file for testing.
It includes several lines of text to demonstrate text extraction.
Feel free to add more paragraphs for a more robust test."""
    pdf.multi_cell(0, 10, sample_text)
    pdf.output(filename)
    print(f"Created sample PDF: {filename}")

create_sample_pdf()

# 2. Download a sample MP3 audio
audio_url = "https://sample-videos.com/audio/mp3/crowd-cheering.mp3"
audio_filename = "sample_audio.mp3"

!wget -q {audio_url} -O {audio_filename}
print(f"Downloaded sample audio: {audio_filename}")

'''import requests

video_url = "https://archive.org/download/tedtalkshorteng/TEDTalkShortENG.mp4"
video_filename = "sample_speech_video.mp4"

response = requests.get(video_url)
if response.status_code == 200:
    with open(video_filename, "wb") as f:
        f.write(response.content)
    print(f"Downloaded {video_filename} ({len(response.content)} bytes)")
else:
    print(f"Failed to download video: {response.status_code}")'''

'''from google.colab import files

files.download('sample.pdf')
files.download('sample_audio.mp3')'''

'''# Download and install Ollama (Linux command)
!curl -fsSL https://ollama.com/install.sh | sh

# Start the Ollama server (background)
!nohup ollama serve &

# (Optionally) install related Python package for easy access
!pip install ollama

# Pull and run a model (e.g., phi3)
!ollama pull phi3'''

!pip install transformers accelerate

from transformers import pipeline
pipe = pipeline("text-generation", model="TinyLlama/TinyLlama-1.1B-Chat-v1.0")  # Use any open model
print(pipe("Say hello to the world!")[0]['generated_text'])

import os
os.environ["LLM_BACKEND"] = "transformers"



!python testing_pipeline.py